---
title: "Coding Assignment 3"
author: "Team 4"
date: "Due: 2024-12-07 23:59"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
library(readxl) # reading in excel file
library(car) # for vif function
library(plotly) # for interactive visualizations
library(gt) # for better looking tables
library(gtsummary) # for better summary statistics
knitr::opts_chunk$set(echo = TRUE)
```

A Florida health insurance company wants to predict annual claims for individual clients. The company pulls a random sample of 100 customers. The owner wishes to charge an actuarially fair premium to ensure a normal rate of return. The owner collects all of their current customer’s health care expenses from the last year and compares them with what is known about each customer’s plan. 

The data on the 100 customers in the sample is as follows:

-	Charges: Total medical expenses for a particular insurance plan (in dollars)
-	Age: Age of the primary beneficiary
-	BMI: Primary beneficiary’s body mass index (kg/m2)
-	Female: Primary beneficiary’s birth sex (0 = Male, 1 = Female)
-	Children: Number of children covered by health insurance plan (includes other dependents as well)
-	Smoker: Indicator if primary beneficiary is a smoker (0 = non-smoker, 1 = smoker)
-	Cities: Dummy variables for each city with the default being Sanford

Answer the following questions using complete sentences and attach all output, plots, etc. within this report.


```{r dataset}
# Bring in the dataset here.
#insurance_data <- read.csv("~/Documents/GitHub/ECO6416_Group04/Insurance_Data_Group4.csv"

insurance <- read.csv("~/Documents/GitHub/ECO6416_Group04/Insurance_Data_Group4.csv")

```


## Question 1

Randomly select 30 observations from the sample and exclude from all modeling. Provide the summary statistics (min, max, std, mean, median) of the quantitative variables for the 70 observations.

```{r q1}
#
set.seed(123)
index <- sample(seq_len(nrow(insurance)), size = 30)
train <- insurance[-index,]
test <- insurance[index,]

train %>% 
  tbl_summary(statistic = list(all_continuous() ~ c("{mean} ({sd})",
                                                    "{median} ({p25}, {p75})",
                                                    "{min}, {max}"),
                              all_categorical() ~ "{n} / {N} ({p}%)"),
              type = all_continuous() ~ "continuous2"
  )
```


## Question 2

Provide the correlation between all quantitative variables

```{r}
included_data <- train %>% select(Charges, Age, BMI, Children)
cor(included_data)
```
Charges and Age have the strongest correlation out of all the variables. All of the rest of the variables (Charges & BMI, Charges & Children, Age & BMI, Age & Children, and BMI & Children) have weak positive correlation. 

## Question 3 

Run a regression that includes all independent variables in the data table. Does the model above violate any of the Gauss-Markov assumptions? If so, what are they and what is the solution for correcting?

```{r}
model <- lm(Charges ~ Age + BMI + Children + Female + Smoker + WinterSprings + WinterPark + Oviedo, data = insurance)
sum<-summary(model)
sum
par(mfrow=c(2,2), mar=c(4,4,2,2))
plot(model)

dwtest(model)
```
The model above violates homoscedasticity, perfect collinearity, and independence. The solution to correcting the heteroscedasticity is... The solution to correcting the multicollinearity is... The solution to correcting the autocorrelation is... 

## Question 4

Implement the solutions from question 3, such as data transformation, along with any other changes you wish. Use the sample data and run a new regression. How have the fit measures changed? How have the signs and significance of the coefficients changed?

```{r q4}
# Log Charges and Charges Squared 
train$LogCharges <- log(train$Charges)
train$ChargesSquared <- train$Charges^2

# Log Age and Age Squared 
train$LogAge <- log(train$Age)
train$AgeSquared <- train$Age^2

# Log Smoker and Smoker Squares 
train$lnSmoker <- log(train$Smoker)
train$SmokerSquared <- train$Smoker^2

# Log BMI and BMI Squared 
train$LogBMI <- log(train$BMI)
train$BMISquared <- train$BMI^2

# Interaction: Children and Age
model_1 <- lm(LogCharges ~LogAge + Children, data = train)
summary(model_1)

# Interaction: Smoker and Female
model_2 <- lm(LogCharges ~ SmokerSquared + Female, data = train)
summary(model_2)

# Interaction: BMI and Oviedo
model_3 <- lm(LogCharges ~train$LogBMI + Oviedo, data = train)
summary(model_3)

# Regression without Children, Female
model_4 <- lm(Charges ~ Age + BMI + Smoker + WinterSprings + WinterPark + Oviedo, data = insurance)
summary(model_4)

# Regression without Age, Smoker
model_5 <- lm(Charges ~ BMI + Children + Female + WinterSprings + WinterPark + Oviedo, data = insurance)
summary(model_5)
#
```



## Question 5

Use the 30 withheld observations and calculate the performance measures for your best two models. Which is the better model? (remember that "better" depends on whether your outlook is short or long run)

```{r q5}
test$LogCharges <- log(test$Charges)
test$LogAge <- log(test$Age)
test$SmokerSquared <- test$Smoker^2

test$model_1_pred <- predict(model_1, newdata= test) %>% exp ()
test$model_2_pred <- predict(model_2, newdata= test) %>% exp ()

test$error_1 <- test$model_1_pred - test$Charges
test$error_2 <- test$model_2_pred - test$Charges

mae <- function(error_vector){error_vector %>%  abs() %>%  mean()}

rmse <- function(error_vector){
   error_vector^2 %>%  mean() %>% sqrt()}

mape <- function(error_vector, actual_vector){
  (error_vector/actual_vector) %>% 
    abs() %>% 
    mean()
}

bias <- mean(test$error_1)
print(bias)
mae <- mae(test$error_1)
print(mae)
mape <- mape(test$error_1, test$Charges)
print(mape)
rmse <- rmse(test$error_1)
print(rmse)

bias <- mean(test$error_2)
print(bias)
mae <- mae(test$Charges, test$model_2_pred)
print(mae)
mape <- mape(test$error_2, test$Charges)
print(mape)
rmse <- rmse(test$Charges, test$model_2_pred)
print(rmse)
```
Long-term, the better model overall is Model 2. Model 2 has significantly lower MAPE and RMSE, which shows a higher level of accuracy and consistency. Both models show bias, but lower MAE, MAPE, and RMSE for Model 2 show that over time it has more accurate predictions.

## Question 6

Provide interpretations of the coefficients, do the signs make sense? Perform marginal change analysis (thing 2) on the independent variables.

```{r}

```


## Question 7

An eager insurance representative comes back with five potential clients. Using the better of the two models selected above, provide the prediction intervals for the five potential clients using the information provided by the insurance rep.

| Customer | Age | BMI | Female | Children | Smoker | City           |
| -------- | --- | --- | ------ | -------- | ------ | -------------- | 
| 1        | 60  | 22  | 1      | 0        | 0      | Oviedo         |
| 2        | 40  | 30  | 0      | 1        | 0      | Sanford        |
| 3        | 25  | 25  | 0      | 0        | 1      | Winter Park    |
| 4        | 33  | 35  | 1      | 2        | 0      | Winter Springs |
| 5        | 45  | 27  | 1      | 3        | 0      | Oviedo         |


```{r}
new_clients <- data.frame(
  Age = c(60, 40, 25, 33, 45),
  BMI = c(22, 30, 25, 35, 27),
  Female = c(1, 0, 0, 1, 1),
  Children = c(0, 1, 0, 2, 3),
  Smoker = c(0, 0, 1, 0, 0),
  City = c("Oviedo", "Sanford", "Winter Park", "Winter Springs", "Oviedo")
)

new_clients$LogAge <- log(new_clients$Age)
new_clients$SmokerSquared <- new_clients$Smoker^2
new_clients$LogCharges

new_clients$model_2_pred <- predict(model_2, newdata = new_clients)

new_clients$lower_PI <- new_clients$model_2_pred - 1.96 * sd(new_clients$model_2_pred)
new_clients$upper_PI <- new_clients$model_2_pred + 1.96 * sd(new_clients$model_2_pred)

print(new_clients)
```

## Question 8
The owner notices that some of the predictions are wider than others, explain why.



## Question 9 
Are there any prediction problems that occur with the five potential clients? If so, explain.

